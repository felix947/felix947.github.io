---
layout: category
author_profile: true
---

## [Introducción al aprendizaje automático](https://github.com/felix947/INF_398)
En esta asignatura aprendí los fundamentos matemáticos detras de los principales modelos de aprendizaje automatico. Tambien puse en practica lo aprendido en Aplicaciones de la matemática en la ingeniería, en donde realicé 2 talleres y 3 desafíos:
- [Predicción de Riesgo Crediticio](https://github.com/felix947/INF_398/blob/main/Desafio_1_ML.ipynb): En este desafío exploraré el problema de predecir si una solicitud de crédito a un banco sera pagada o no, una versión binaria de lo que se denomina análisis de riesgo, que es su vez una de las aplicaciones mas comunes del aprendizaje automatico en la industria financiera.
- [Predicción de precio](https://github.com/felix947/INF_398/blob/main/Desafi%CC%81o_2_ML.ipynb): En esta competencia, realicé modelo que sugiera automáticamente los precios correctos de los productos. Se le proporcionaron descripciones de texto y detalles como la categoria del producto, el nombre de la marca y la condición del artículo. Aquí ocupé librerías como nltk para el analisis de sentimentos dentro de la descripcion de texto junto el analisis usual de texto ocupando CountVectorizer de scikit-learn.
- [Sobrevivientes](https://github.com/felix947/INF_398/blob/main/Desafio_3_ML.ipynb): El desafío es crear un modelo que use datos de las primeras 24 horas de cuidados intensivos para predecir la supervivencia o no del paciente.
- [Taller 1](https://github.com/felix947/INF_398/blob/main/Taller_1_ML.ipynb): Se validó la siguiente hipótesis: Selección de Modelos: El numero de variables con que se entrena un modelo es inversamente proporcional al error de pruebas y directamente proporcional a la diferencia entre el error de validación y el error de entrenamiento.
- [Taller 2](https://github.com/felix947/INF_398/blob/main/Taller_2_ML.ipynb): Se validó la siguiente hipótesis: Métodos de Filtrado en Regresión. Para el modelo de regresión lineal, un filtrado individual de atributos basado en el Z-SCORE permite encontrar el conjunto de K variables que minimizan el error de prediccion.
